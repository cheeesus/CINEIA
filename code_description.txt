ç›®å½•ç»“æ„ï¼ˆ./DNN_TorchFM_TTowerï¼‰
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ pytorch_model.py
â”‚   â”œâ”€â”€ ranking
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ custom_deepfm.py
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py
â”‚   â”‚   â”œâ”€â”€ infer_ranking.py
â”‚   â”‚   â”œâ”€â”€ torchfm
â”‚   â”‚   â”‚   â””â”€â”€ deepfm.py
â”‚   â”‚   â”œâ”€â”€ torchfm_ranker.py
â”‚   â”‚   â””â”€â”€ train_ranking.py
â”‚   â””â”€â”€ recall
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cold_start.py
â”‚       â”œâ”€â”€ train_incremental.py
â”‚       â”œâ”€â”€ train_two_tower.py
â”‚       â””â”€â”€ two_tower.py
â”œâ”€â”€ readme.md
â”œâ”€â”€ readyou_description_CN.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ saved_model
â”‚   â””â”€â”€ dnn_recommender.pt
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ incremental.py
â”‚   â””â”€â”€ interactive_demo.py
â””â”€â”€ service
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ recommender copy.py
    â””â”€â”€ recommender.py


æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š

===== æ–‡ä»¶: ./DNN_TorchFM_TTower/readyou_description_CN.md =====
## The Process of run the Demo Recommandation System
> 05/01/2025

## I recommand you to use the following steps to run the recommender system.
## it's better to use the Conda env to run the recommender system.

python -m venv rec_python10
python activate rec_python10/scripts/activate

# 1. install the requirment packages
pip install --upgrade -r requirements.txt

# 3. retrain the call back model 
python -m models.recall.train_two_tower --epochs 3 --batch 128

# 4. retraion the re-rank model
python -m models.ranking.train_ranking --epochs 3

# 5. check the recommendation results
python -m service/recommender.py 1001 --top 10

# exit the conda env
deactivate

### Backup code for checkout the database
psql -h postgresql-yannr.alwaysdata.net -p 5432 -U yannr_01 -d yannr_00
Project1234



æŸ¥çœ‹æ‰€æœ‰è¡¨çš„å­—æ®µã€æ•°æ®ç±»å‹ã€æ˜¯å¦å¯ç©ºã€é»˜è®¤å€¼


SELECT
    table_name AS è¡¨å,
    column_name AS å­—æ®µå,
    data_type AS æ•°æ®ç±»å‹,
    is_nullable AS æ˜¯å¦å¯ç©º,
    column_default AS é»˜è®¤å€¼
FROM
    information_schema.columns
WHERE
    table_schema = 'public'
ORDER BY
    table_name, ordinal_position;

===== æ–‡ä»¶: ./DNN_TorchFM_TTower/readme.md =====
# CINEIA â€“ AI Back-End (Two-Tower Recall + DeepFM Re-Rank)

This branch contains the complete Python code required to **train**, **serve** and **try** the recommendation engine that will later be queried by the front-end.

###  Quick start

```bash
# 0  move into the project
cd DNN_TorchFM_TTower

# 1  install dependencies (CPU PyTorch by default)
pip install --upgrade -r requirements.txt

# 2  (optional) edit models/config.py to point to your PostgreSQL

# 3  train / retrain the Two-Tower recall model
python -m DNN_TorchFM_TTower.models.recall.train_two_tower  --epochs 3 --batch 128

# 4  train / retrain the DeepFM re-rank model
python -m DNN_TorchFM_TTower.models.ranking.train_ranking   --epochs 3

# 5  run the interactive CLI demo (cold-start â†’ warm-start â†’ incremental retrain)
python -m DNN_TorchFM_TTower.scripts.interactive_demo

```

### Project layout (high level)
```bash
models/
â”‚
â”œâ”€ config.py             â† DB credentials
â”œâ”€ db.py                 â† thin PostgreSQL helper
â”œâ”€ pytorch_model.py      â† Two-Tower network
â”‚
â”œâ”€ recall/               â† coarse recall layer
â”‚   â”œâ”€ cold_start.py
â”‚   â”œâ”€ two_tower.py      â† inference helper
â”‚   â”œâ”€ train_two_tower.py
â”‚   â””â”€ train_incremental.py
â”‚
â””â”€ ranking/              â† fine re-rank layer
    â”œâ”€ custom_deepfm.py  â† pure-PyTorch DeepFM
    â”œâ”€ feature_engineer.py
    â”œâ”€ train_ranking.py
    â””â”€ infer_ranking.py
service/
â”‚   â”œâ”€ recommender.py    â† single python entry, returns Top-N ids
â”‚   â””â”€ api.py (optional) â† FastAPI REST wrapper
scripts/
    â””â”€ interactive_demo.py
saved_model/             â† trained weights (auto-created)
requirements.txt
```

### AI pipeline
```bash
new user
   â”‚ cold_start(pop-REC+diversity)
   â–¼
movie ids â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚
old user                 â–¼
(view history) â†’ Two-Tower recall (300 ids, score)
                         â”‚
                         â–¼
                 DeepFM re-rank (uses recall_score + 3 dense feats)
                         â”‚
                         â–¼
                    Top-N  personalised list
```

### Database quick reference
-- inspect public schema
```sql
SELECT table_name   AS "Table",
       column_name  AS "Column",
       data_type    AS "Type",
       is_nullable  AS "NULL?",
       column_default AS "Default"
FROM   information_schema.columns
WHERE  table_schema = 'public'
ORDER  BY table_name, ordinal_position;
```

===== æ–‡ä»¶: ./DNN_TorchFM_TTower/scripts/interactive_demo.py =====
#!/usr/bin/env python3
"""
scripts/interactive_demo.py
CLI äº¤äº’å¼æ¨èæ¼”ç¤º interactive demo

æµç¨‹ï¼š
  1. è¾“å…¥ä¸€ä¸ªç”¨æˆ· IDï¼ˆè‹¥ä¸å­˜åœ¨è‡ªåŠ¨æ’å…¥ï¼‰
  2. è°ƒç”¨ service.recommender æ¨è TOP_N éƒ¨ç”µå½±
  3. ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©è‹¥å¹²éƒ¨æƒ³çœ‹çš„ â†’ å†™å…¥ view_history
  4. æ¯ LOOP_FOR_RETRAIN è½®ï¼š
        â€¢ å¬å›ä¾§å¢é‡è®­ç»ƒ 1 epoch
        â€¢ ç²¾æ’ä¾§å¢é‡è®­ç»ƒ 1 epoch
  5. å›åˆ°æ­¥éª¤ 2ï¼Œç›´åˆ°è¾“å…¥ q / quit é€€å‡º
"""

from typing import List

# ------- readline åœ¨ Linux / macOS é»˜è®¤æœ‰ï¼›Windows æ²¡æœ‰ä¹Ÿä¸å½±å“ -------
try:
    import readline  # noqa: F401
except ImportError:
    pass

from DNN_TorchFM_TTower.models.db import (
    fetchone_dict, execute_sql,
    get_movie_titles, get_user_view_count,
)

from DNN_TorchFM_TTower.models.recall.train_incremental import incremental_train as recall_inc_train
from DNN_TorchFM_TTower.models.ranking.train_ranking import main as ranking_train_main
from DNN_TorchFM_TTower.service.recommender import recommend_movies_for_user

TOP_N = 10
LOOP_FOR_RETRAIN = 3      # æ¯ 3 è½®åšä¸€æ¬¡å¢é‡é‡è®­ï¼ˆå¯è°ƒä¸º 0 å…³é—­ï¼‰


# ------------------------------------------------------------------ #
#                 DB å¸®åŠ©å‡½æ•°ï¼šå»ºç”¨æˆ· / æ’è§‚çœ‹è®°å½•                    #
# ------------------------------------------------------------------ #
def ensure_user(user_id: int):
    if not fetchone_dict("SELECT 1 FROM users WHERE id=%s", (user_id,)):
        execute_sql(
            "INSERT INTO users (id, email, password_hash) VALUES (%s, %s, %s)",
            (user_id, f"cli_{user_id}@demo.com", b"hash_placeholder"),
        )
        print(f"âœ… new user created {user_id}")


def insert_views(user_id: int, movie_ids: List[int]):
    for mid in movie_ids:
        execute_sql(
            "INSERT INTO view_history (user_id, movie_id) VALUES (%s, %s)",
            (user_id, mid),
        )


# ------------------------------------------------------------------ #
#                             äº¤äº’å‡½æ•°                               #
# ------------------------------------------------------------------ #
def choose_movies(candidates: List[int], titles: dict[int, str]) -> List[int] | None:
    print("\nPlease enter the serial number of the movie you want to watch (separated by Spaces), or exit with q:")
    for i, m in enumerate(candidates, 1):
        print(f"[{i:02}] ID={m} | {titles.get(m, 'Unknown')} ")

    while True:
        raw = input("your choices: ").strip().lower()
        if raw in {"q", "quit"}:
            return None
        try:
            idxs = [int(s) for s in raw.split()]
            chosen = [candidates[i - 1] for i in idxs if 1 <= i <= len(candidates)]
            return chosen
        except ValueError:
            print("The input format is incorrect. Please re-enter")


# ------------------------------------------------------------------ #
#                         å¢é‡è®­ç»ƒå°è£…                                #
# ------------------------------------------------------------------ #
def incremental_retrain():
    print("\n Incremental training begins (recall 1 epoch + rerank 1 epoch)...")
    recall_inc_train(neg_ratio=1, epochs=1)
    ranking_train_main(epochs=1, batch_size=4096, neg_ratio=1)
    print("incremental training fini\n")


# ------------------------------------------------------------------ #
#                           ä¸»å¾ªç¯                                   #
# ------------------------------------------------------------------ #
def interactive_loop(user_id: int):
    ensure_user(user_id)
    loop_cnt = 0

    while True:
        viewed = get_user_view_count(user_id)
        print(f"\n=== user {user_id} has watched {viewed} films ===")

        mids, scores, strategy = recommend_movies_for_user(user_id, n_final=TOP_N)
        if not mids:
            print("  unable to fetch datas, please check the database connection")
            break

        title_map = get_movie_titles(mids)
        chosen = choose_movies(mids, title_map)
        if chosen is None:
            print("\nğŸ‘‹ Bye~")
            break

        insert_views(user_id, chosen)
        print(f" å·²è®°å½•è§‚çœ‹ {len(chosen)} éƒ¨å½±ç‰‡ã€‚")
        loop_cnt += 1

        # ---- æ¡ä»¶è§¦å‘å¢é‡è®­ç»ƒ ----
        if LOOP_FOR_RETRAIN and loop_cnt % LOOP_FOR_RETRAIN == 0:
            incremental_retrain()



# ------------------------------------------------------------------ #
#                                 main                               #
# ------------------------------------------------------------------ #
if __name__ == "__main__":
    try:
        uid = int(input("Please enter the user ID (fill in any integer for a new one) : ").strip())
    except ValueError:
        print(" x The user ID must be an integer")
        exit(1)

    interactive_loop(uid)


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/scripts/incremental.py =====
import numpy as np
import torch
from pathlib import Path

from DNN_TorchFM_TTower.models.db import fetchone_dict
from DNN_TorchFM_TTower.models.ranking.feature_engineer import build_infer_df
from DNN_TorchFM_TTower.models.ranking.custom_deepfm import DeepFM

BASE_DIR = Path(__file__).resolve().parents[3]
MODEL_PATH = BASE_DIR / "saved_model" / "deepfm_ranker.pt"

def _vocab_sizes():
    mu = fetchone_dict("SELECT MAX(id) AS m FROM users")["m"] or 0
    mm = fetchone_dict("SELECT MAX(id) AS m FROM movies")["m"] or 0
    mg = fetchone_dict("SELECT MAX(id) AS m FROM genres")["m"] or 0
    return [mu + 2, mm + 2, mg + 2]

def _load_model(field_dims, num_dense):
    model = DeepFM(field_dims, num_dense)
    if MODEL_PATH.exists():
        state = torch.load(MODEL_PATH, map_location="cpu")
        model.load_state_dict(state, strict=False)
        model.eval()
        return model
    return None

def rank_candidates(user_id, movie_ids, recall_scores, top_n=10):
    if not movie_ids:
        return []
    df = build_infer_df(user_id, movie_ids, recall_scores)
    sparse_cols = ["user_id", "movie_id", "genre_id"]
    dense_cols  = ["recall_score", "vote_average", "popularity", "age"]
    field_dims  = _vocab_sizes()
    model = _load_model(field_dims, num_dense=len(dense_cols))
    if model is None:
        idx = np.argsort(-np.array(recall_scores))[:top_n]
        return list(np.array(movie_ids)[idx])
    xs = torch.tensor(df[sparse_cols].values, dtype=torch.long)
    xd = torch.tensor(df[dense_cols].values, dtype=torch.float32)
    with torch.no_grad():
        scores = torch.sigmoid(model(xs, xd)).numpy()
    df["score"] = scores
    return df.sort_values("score", ascending=False).head(top_n)["movie_id"].tolist()

if __name__ == "__main__":
    import argparse
    from DNN_TorchFM_TTower.models.recall.two_tower import load_model, recommend_warm_start
    from DNN_TorchFM_TTower.models.db import get_movie_titles
    parser = argparse.ArgumentParser()
    parser.add_argument("user_id", type=int)
    args = parser.parse_args()
    tower = load_model()
    cand_ids, cand_scores = recommend_warm_start(tower, args.user_id, top_n=300)
    ranked = rank_candidates(args.user_id, cand_ids, cand_scores, top_n=10)
    titles = get_movie_titles(ranked)
    for i, mid in enumerate(ranked, 1):
        print(f"{i:02}. {titles.get(mid,'Unknown')} (ID={mid})")


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/config.py =====
# models/config.py
DB_NAME = "yannr_00"
DB_USER = "yannr_01"
DB_PASSWORD = "Projet1234"
DB_HOST = "postgresql-yannr.alwaysdata.net"
DB_PORT = 5432




===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/pytorch_model.py =====
import torch
import torch.nn as nn

class TwoTowerMLPModel(nn.Module):
    def __init__(self, num_users, num_movies, embedding_dim=32, hidden_dim=64):
        super(TwoTowerMLPModel, self).__init__()
        self.user_embedding = nn.Embedding(num_users + 1, embedding_dim)
        self.movie_embedding = nn.Embedding(num_movies + 1, embedding_dim)

        self.fc1 = nn.Linear(embedding_dim * 2, hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
        self.fc2 = nn.Linear(hidden_dim, 1)  # logit 

    def forward(self, user_ids, movie_ids):
        user_vec = self.user_embedding(user_ids)     # (batch_size, embedding_dim)
        movie_vec = self.movie_embedding(movie_ids)  # (batch_size, embedding_dim)

        x = torch.cat([user_vec, movie_vec], dim=1)  # (batch_size, embedding_dim*2)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        logit = self.fc2(x).squeeze(1)              # (batch_size,)
        return logit  # raw logits (BCEWithLogitsLoss)


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/db.py =====
# DNN_TorchFM_TTower\models\db.py
import psycopg2
from psycopg2.extras import RealDictCursor
from collections import Counter
from DNN_TorchFM_TTower.models.config import DB_NAME, DB_USER, DB_PASSWORD, DB_HOST, DB_PORT
from typing import List  # <-- æ–°å¢

def get_connection():
    return psycopg2.connect(
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        host=DB_HOST,
        port=DB_PORT
    )

def fetchall_dict(query, params=None):
    with get_connection() as conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query, params)
            return cur.fetchall()

def fetchone_dict(query, params=None):
    with get_connection() as conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query, params)
            return cur.fetchone()

def get_movie_titles(movie_ids):
    query = "SELECT id, title FROM movies WHERE id = ANY(%s)"
    rows = fetchall_dict(query, (movie_ids,))
    return {row["id"]: row["title"] for row in rows}

def get_max_user_id():
    row = fetchone_dict("SELECT MAX(id) as m FROM users")
    return row["m"] or 0

def get_max_movie_id():
    row = fetchone_dict("SELECT MAX(id) as m FROM movies")
    return row["m"] or 0

def get_all_movie_ids_with_language():
    """
    è¿”å› (ç”µå½±id, original_language) å…ƒç»„åˆ—è¡¨ï¼Œä»…è¿”å›æœ‰ original_language çš„è®°å½•ã€‚
    """
    rows = fetchall_dict("SELECT id, original_language FROM movies")
    return [(r["id"], r["original_language"]) for r in rows if r["original_language"]]

def get_user_view_languages(user_id):
    """
    æ ¹æ® view_history è¡¨ï¼Œç»Ÿè®¡ç”¨æˆ·çœ‹è¿‡çš„ç”µå½±çš„è¯­è¨€åˆ†å¸ƒï¼Œå¹¶å–æœ€å¸¸è§çš„å‰2ç§è¯­è¨€ã€‚
    """
    query = """
        SELECT m.original_language
        FROM view_history v
        JOIN movies m ON v.movie_id = m.id
        WHERE v.user_id = %s
    """
    rows = fetchall_dict(query, (user_id,))
    lang_counter = Counter(r["original_language"] for r in rows if r["original_language"])
    if not lang_counter:
        return set()
    # å‡è®¾æˆ‘ä»¬åªå…³å¿ƒæœ€å¸¸è§çš„2ç§è¯­è¨€
    top_languages = {lang for lang, _ in lang_counter.most_common(2)}
    return top_languages

def get_user_view_count(user_id):
    """
    è¿”å›ç”¨æˆ·åœ¨ view_history è¡¨ä¸­çš„è§‚å½±æ•°é‡ã€‚è‹¥ä¸º 0ï¼Œåˆ™è¡¨ç¤ºæ–°ç”¨æˆ·ï¼ˆæ— å†å²è®°å½•ï¼‰ã€‚
    """
    query = "SELECT COUNT(*) as cnt FROM view_history WHERE user_id = %s"
    row = fetchone_dict(query, (user_id,))
    return row["cnt"] if row else 0

def get_top_rated_movies(limit=10):
    """
    æ ¹æ® movies è¡¨é‡Œçš„ vote_average å­—æ®µï¼Œè·å–è¯„åˆ†æœ€é«˜çš„ç”µå½± ID åˆ—è¡¨ã€‚
    å¦‚æœæƒ³è€ƒè™‘æŠ•ç¥¨æ•°é‡ï¼Œä¹Ÿå¯ä»¥æŒ‰ (vote_average DESC, vote_count DESC) æ¥æ’åºã€‚
    """
    query = """
        SELECT id
        FROM movies
        WHERE vote_count > 0
        ORDER BY vote_average DESC, vote_count DESC
        LIMIT %s
    """
    rows = fetchall_dict(query, (limit,))
    return [r["id"] for r in rows]

def execute_sql(query, params=None):
    with get_connection() as conn:
        with conn.cursor() as cur:
            cur.execute(query, params)
            conn.commit()

def get_user_preferences(user_id: int) -> List[int]:
    """
    Returns a list of genre IDs the user has selected in their profile.
    """
    query = "SELECT genre_id FROM user_preferences WHERE user_id = %s"
    rows = fetchall_dict(query, (user_id,))
    return [r["genre_id"] for r in rows]

===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/__init__.py =====


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/recall/cold_start.py =====
# models/recall/cold_start.py
import random
from DNN_TorchFM_TTower.models.db import fetchall_dict

def recommend_cold_start(top_n=10):
    """
    é’ˆå¯¹æ— å†å²ç”¨æˆ·(å†·å¯åŠ¨)ï¼šå…ˆé€‰ä¸€æ‰¹é«˜è¯„åˆ†çƒ­é—¨ç”µå½±ï¼Œå†éšæœºæŠ½å– top_nã€‚
    ç¤ºä¾‹ï¼šæˆ‘ä»¬å‡è®¾åœ¨ movies è¡¨ä¸­æœ‰ vote_average, vote_count å­—æ®µã€‚
    """
    query = """
        SELECT id
        FROM movies
        WHERE vote_count > 0
        ORDER BY vote_average DESC, vote_count DESC
        LIMIT 50
    """
    rows = fetchall_dict(query)
    if not rows:
        return []
    candidate_ids = [r["id"] for r in rows]
    
    # ä»è¿™ 50 éƒ¨è¯„åˆ†æœ€é«˜çš„å½±ç‰‡é‡ŒéšæœºæŠ½ top_n
    if len(candidate_ids) <= top_n:
        return candidate_ids
    return random.sample(candidate_ids, top_n)


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/recall/train_incremental.py =====
# models/recall/train_incremental.py
"""
Two-Tower æ¨¡å‹å¢é‡è®­ç»ƒè„šæœ¬
= åŸ train_incremental.pyï¼Œä½†ä» train_two_tower å¯¼å…¥æ•°æ®æ„é€ å·¥å…·
"""

import os
import time

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from DNN_TorchFM_TTower.models.db import fetchone_dict
from DNN_TorchFM_TTower.models.pytorch_model import TwoTowerMLPModel
from DNN_TorchFM_TTower.models.recall.train_two_tower import (
    generate_training_data,
    RecommendationDataset,
)

MODEL_PATH = "saved_model/dnn_recommender.pt"


def incremental_train(neg_ratio: int = 1,
                      epochs: int = 3,
                      lr: float = 5e-4):
    """
    â€¢ ç”¨æœ€æ–°è¡Œä¸ºé‡æ–°æ„é€ æ­£/è´Ÿæ ·æœ¬  
    â€¢ åœ¨å·²æœ‰æ¨¡å‹å‚æ•°åŸºç¡€ä¸Šå°æ­¥è®­ç»ƒ
    """
    df = generate_training_data(neg_ratio)
    if df.empty:
        print("[incremental] æ— è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
        return

    loader = DataLoader(RecommendationDataset(df),
                        batch_size=64, shuffle=True)

    max_u = fetchone_dict("SELECT MAX(id) AS m FROM users")["m"] or 0
    max_m = fetchone_dict("SELECT MAX(id) AS m FROM movies")["m"] or 0

    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(
            "[incremental] åŸºç¡€æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæ•´è®­ç»ƒ"
        )

    model = TwoTowerMLPModel(max_u, max_m,
                             embedding_dim=32, hidden_dim=64)
    model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))

    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)

    model.train()
    tic = time.time()
    for ep in range(1, epochs + 1):
        losses = []
        for u, m, y in loader:
            optimizer.zero_grad()
            loss = criterion(model(u, m), y)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())
        print(f"[incremental] epoch {ep}/{epochs}  "
              f"loss={np.mean(losses):.4f}")

    torch.save(model.state_dict(), MODEL_PATH)
    print(f"[incremental] Î” è®­ç»ƒå®Œæˆï¼Œç”¨æ—¶ {time.time() - tic:.1f}s")


if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--epochs", type=int, default=3)
    ap.add_argument("--neg_ratio", type=int, default=1)
    args = ap.parse_args()

    incremental_train(neg_ratio=args.neg_ratio, epochs=args.epochs)


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/recall/train_two_tower.py =====
# models/recall/train_two_tower.py
"""
Two-Tower å¬å›æ¨¡å‹ç¦»çº¿è®­ç»ƒè„šæœ¬
= æ—§ç‰ˆ train.pyï¼Œè°ƒæ•´äº† import è·¯å¾„å¹¶æ”¹å
"""
import os
import random
import time
from pathlib import Path
from typing import List, Dict, Set

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tqdm import tqdm  # â† æ–°å¢

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

from DNN_TorchFM_TTower.models.db import fetchall_dict, fetchone_dict
from DNN_TorchFM_TTower.models.pytorch_model import TwoTowerMLPModel

# ---------------------------------------------------------------------------
#                     å›ºå®š saved_model ç›®å½•åˆ°åŒ…æ ¹ä¸‹                           #
# ---------------------------------------------------------------------------
PROJECT_ROOT = Path(__file__).resolve().parents[3]          # â€¦/CINEIA/DNN_TorchFM_TTower
SAVE_DIR     = PROJECT_ROOT / "saved_model"
SAVE_DIR.mkdir(parents=True, exist_ok=True)
MODEL_PATH   = SAVE_DIR / "dnn_recommender.pt"


# os.makedirs("saved_model", exist_ok=True)

# --------------------------------------------------------------------------- #
#                            æ•°æ®æå– / ç‰¹å¾æ„é€                                #
# --------------------------------------------------------------------------- #
def get_all_movies() -> List[int]:
    return [r["id"] for r in fetchall_dict("SELECT id FROM movies")]


def get_movie_genres() -> Dict[int, Set[int]]:
    rows = fetchall_dict("SELECT movie_id, genre_id FROM movie_genre")
    m2g = {}
    for r in rows:
        m2g.setdefault(r["movie_id"], set()).add(r["genre_id"])
    return m2g


def get_positive_samples() -> pd.DataFrame:
    """
    view_history ä¸­çš„æ¯æ¡è§‚çœ‹è®°å½•è§†ä¸ºæ­£æ ·æœ¬ (label=1)
    """
    rows = fetchall_dict("SELECT user_id, movie_id FROM view_history")
    if not rows:
        return pd.DataFrame(columns=["user_id", "movie_id", "rating"])
    df = pd.DataFrame(rows)
    df["rating"] = 1.0
    return df


def generate_training_data(neg_ratio: int = 1) -> pd.DataFrame:
    """
    æ­£æ ·æœ¬ï¼šview_history  
    è´Ÿæ ·æœ¬ï¼šåŒç”¨æˆ·æœªçœ‹è¿‡ï¼Œä¸”é¢˜æä¸å·²çœ‹å½±ç‰‡ä¸é‡å çš„éšæœºé‡‡æ ·
    """
    pos_df = get_positive_samples()
    if pos_df.empty:
        return pos_df

    all_movies = set(get_all_movies())
    movie_genres = get_movie_genres()

    user_pos = pos_df.groupby("user_id")["movie_id"].apply(set).to_dict()
    user_genres = {
        u: {g for m in ms for g in movie_genres.get(m, set())}
        for u, ms in user_pos.items()
    }

    neg_records = []
    for u, pos in user_pos.items():
        watched_genres = user_genres.get(u, set())
        # candidate: æœªçœ‹ & é¢˜æä¸é‡å 
        cand = [m for m in all_movies - pos
                if movie_genres.get(m, set()).isdisjoint(watched_genres)]
        num_neg = min(len(cand), neg_ratio * len(pos))
        if num_neg:
            neg_records += [{"user_id": u, "movie_id": m, "rating": 0.0}
                            for m in random.sample(cand, num_neg)]

    neg_df = pd.DataFrame(neg_records)
    train_df = pd.concat([pos_df, neg_df], ignore_index=True)
    return train_df


class RecommendationDataset(Dataset):
    def __init__(self, df: pd.DataFrame):
        self.users = torch.tensor(df["user_id"].values, dtype=torch.long)
        self.movies = torch.tensor(df["movie_id"].values, dtype=torch.long)
        self.labels = torch.tensor(df["rating"].values, dtype=torch.float32)

    def __len__(self):
        return len(self.users)

    def __getitem__(self, idx):
        return self.users[idx], self.movies[idx], self.labels[idx]


def _get_max_ids() -> tuple[int, int]:
    mu = fetchone_dict("SELECT MAX(id) AS m FROM users")["m"] or 0
    mm = fetchone_dict("SELECT MAX(id) AS m FROM movies")["m"] or 0
    return mu, mm


# --------------------------------------------------------------------------- #
#                               è®­ ç»ƒ ä¸» ç¨‹ åº                                 #
# --------------------------------------------------------------------------- #
def main(epochs: int = 3, batch_size: int = 128, neg_ratio: int = 1):
    df = generate_training_data(neg_ratio)
    if df.empty:
        print("[train_two_tower] âŒ è®­ç»ƒé›†ä¸ºç©º")
        return

    print(f"[train_two_tower] æ ·æœ¬ {len(df)} | ç”¨æˆ· {df['user_id'].nunique()} | ç”µå½± {df['movie_id'].nunique()}")

    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
    train_loader = DataLoader(RecommendationDataset(train_df),
                              batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(RecommendationDataset(val_df),
                            batch_size=batch_size, shuffle=False)

    max_u, max_m = _get_max_ids()
    model = TwoTowerMLPModel(max_u, max_m, embedding_dim=32, hidden_dim=64)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)

    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)

    best_val = float("inf")
    for ep in range(1, epochs + 1):
        ep_start = time.time()
        model.train()
        tloss = []

        for u, m, y in tqdm(train_loader, desc=f"Epoch {ep}/{epochs}", ncols=80):
            u, m, y = u.to(device), m.to(device), y.to(device)
            optimizer.zero_grad()
            loss = criterion(model(u, m), y)
            loss.backward()
            optimizer.step()
            tloss.append(loss.item())

        avg_t = np.mean(tloss)

        # ---------- éªŒè¯ ----------
        model.eval()
        vloss = []
        with torch.no_grad():
            for u, m, y in val_loader:
                u, m, y = u.to(device), m.to(device), y.to(device)
                vloss.append(criterion(model(u, m), y).item())
        avg_v = np.mean(vloss)

        print(f"[Ep {ep:02}] train={avg_t:.4f}  val={avg_v:.4f}  time={time.time()-ep_start:.1f}s")

        if avg_v < best_val:
            best_val = avg_v
            torch.save(model.state_dict(), MODEL_PATH)
            print("   â†³  Model saved")

    print(f"[train_two_tower] Doneï¼Œbest val={best_val:.4f}")


if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--epochs", type=int, default=3)        # é»˜è®¤ä¸º 3
    ap.add_argument("--batch", type=int, default=128)
    ap.add_argument("--neg_ratio", type=int, default=1)
    args = ap.parse_args()

    main(epochs=args.epochs, batch_size=args.batch, neg_ratio=args.neg_ratio)

===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/recall/two_tower.py =====
"""
Two-Tower recall model inference logic

æŠŠåŸå…ˆçš„ warm_start.py + infer.py åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶ï¼Œä¾› service å±‚è°ƒç”¨ï¼š
    from models.recall.two_tower import load_model, recommend_warm_start
"""

import time
from pathlib import Path
from typing import List, Tuple

import numpy as np
import torch

from DNN_TorchFM_TTower.models.db import (
    get_max_user_id,
    get_max_movie_id,
    get_all_movie_ids_with_language,
    get_user_view_languages,
)
from DNN_TorchFM_TTower.models.pytorch_model import TwoTowerMLPModel

def load_model(model_path: str | None = None, *, embedding_dim: int = 32) -> TwoTowerMLPModel:
    """åŠ è½½ Two-Towerï¼Œå¹¶å¯¹â€œæ–°ç”¨æˆ· / æ–°ç”µå½±â€åšå®‰å…¨æ‰©å®¹æ‹·è´ã€‚"""
    if model_path is None:
        model_path = Path(__file__).resolve().parents[3] / "saved_model" / "dnn_recommender.pt"
    model_path = Path(model_path)

    # â”€â”€ 1. å–å¾—æœ€æ–° vocab size â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    max_u = get_max_user_id()
    max_m = get_max_movie_id()
    model = TwoTowerMLPModel(max_u, max_m, embedding_dim=embedding_dim, hidden_dim=64)

    # å¦‚æœè¿˜æ²¡æœ‰è®­ç»ƒè¿‡ï¼Œç›´æ¥è¿”å›éšæœºåˆå§‹æ¨¡å‹
    if not model_path.exists():
        return model.eval()

    # â”€â”€ 2. æ–­ç‚¹æƒé‡åŠ è½½ï¼ˆå¸¦æ‰©å®¹ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    state = torch.load(model_path, map_location="cpu")

    # helperï¼šæŠŠæ—§æƒé‡æ‹·è¿›æ–°çš„ embeddingï¼Œå‰©ä¸‹çš„è¡Œä¿æŒéšæœºåˆå§‹åŒ–
    def _copy(old_w, new_w):
        rows = min(old_w.size(0), new_w.size(0))
        new_w[:rows].data.copy_(old_w[:rows])

    if "user_embedding.weight" in state:
        _copy(state["user_embedding.weight"], model.user_embedding.weight)
    if "movie_embedding.weight" in state:
        _copy(state["movie_embedding.weight"], model.movie_embedding.weight)

    # å…¶ä½™å±‚å½¢çŠ¶ç›¸åŒï¼Œç›´æ¥åŠ è½½ï¼ˆstrict=False è·³è¿‡åˆšæ‰å¤„ç†è¿‡çš„ä¸¤ä¸ª keyï¼‰
    for k in ["user_embedding.weight", "movie_embedding.weight"]:
        state.pop(k, None)
    model.load_state_dict(state, strict=False)

    model.eval()
    return model


def recommend_warm_start(model: TwoTowerMLPModel, user_id: int, top_n: int = 10) -> Tuple[List[int], List[float]]:
    tic = time.time()
    preferred_langs = get_user_view_languages(user_id)
    all_movies = get_all_movie_ids_with_language()
    if preferred_langs:
        candidate_movies = [m for m, lang in all_movies if lang in preferred_langs]
    else:
        candidate_movies = [m for m, _ in all_movies]
    if not candidate_movies:
        return [], []
    movie_tensor = torch.tensor(candidate_movies, dtype=torch.long)
    user_tensor = torch.full((len(candidate_movies),), user_id, dtype=torch.long)
    with torch.no_grad():
        logits = model(user_tensor, movie_tensor)
        scores = torch.sigmoid(logits).numpy().flatten()
    top_idx = np.argsort(-scores)[:top_n]
    top_movie_ids = np.array(candidate_movies)[top_idx]
    top_scores = scores[top_idx]
    print(f"[two_tower] Inference finished in {time.time() - tic:.2f}s")
    return top_movie_ids.tolist(), top_scores.tolist()

if __name__ == "__main__":
    import argparse
    from DNN_TorchFM_TTower.models.db import get_movie_titles
    ap = argparse.ArgumentParser()
    ap.add_argument("user_id", type=int)
    ap.add_argument("--top_n", type=int, default=10)
    args = ap.parse_args()
    mdl = load_model()
    mids, scs = recommend_warm_start(mdl, args.user_id, args.top_n)
    title_map = get_movie_titles(mids)
    print(f"\nTop {args.top_n} recommendations for user {args.user_id}:")
    for idx, (mid, score) in enumerate(zip(mids, scs), start=1):
        print(f"  {idx:02}. ID={mid:<6}  {title_map.get(mid, 'Unknown'):<40}  score={score:.4f}")


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/recall/__init__.py =====


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/train_ranking.py =====
import os
import argparse
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from tqdm import tqdm

from DNN_TorchFM_TTower.models.db import fetchone_dict
from DNN_TorchFM_TTower.models.ranking.feature_engineer import build_training_df
from DNN_TorchFM_TTower.models.ranking.custom_deepfm import DeepFM

# Ensure save directory exists
os.makedirs("saved_model", exist_ok=True)
MODEL_PATH = "saved_model/deepfm_ranker.pt"

def _vocab_sizes():
    mu = fetchone_dict("SELECT MAX(id) AS m FROM users")["m"] or 0
    mm = fetchone_dict("SELECT MAX(id) AS m FROM movies")["m"] or 0
    mg = fetchone_dict("SELECT MAX(id) AS m FROM genres")["m"] or 0
    # å››ä¸ªç¨€ç–åŸŸï¼šuser_id, movie_id, genre_id, pref_genre_id
    return [mu + 2, mm + 2, mg + 2, mg + 2]

def _to_tensor(df, sparse_cols, dense_cols):
    Xs = torch.tensor(df[sparse_cols].values, dtype=torch.long)
    Xd = torch.tensor(df[dense_cols].values, dtype=torch.float32)
    y  = torch.tensor(df["label"].values, dtype=torch.float32)
    return TensorDataset(Xs, Xd, y)

def main(epochs=3, batch_size=2048, neg_ratio=1):
    df = build_training_df(neg_ratio)
    if df.empty:
        print("[train_ranking] no training data")
        return

    # è®­ç»ƒæ—¶ recall_score è®¾ä¸ºå¸¸æ•° 0.0
    df["recall_score"] = 0.0

    sparse_cols = ["user_id", "movie_id", "genre_id", "pref_genre_id"]
    dense_cols  = ["recall_score", "vote_average", "popularity", "age"]

    print(f"[train_ranking] samples={len(df)}  pos:negâ‰ˆ1:{neg_ratio}")

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    tr_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
    train_loader = DataLoader(_to_tensor(tr_df, sparse_cols, dense_cols), 
                              batch_size=batch_size, shuffle=True)
    val_loader   = DataLoader(_to_tensor(val_df, sparse_cols, dense_cols),   
                              batch_size=batch_size, shuffle=False)

    # æ„å»º DeepFM æ¨¡å‹
    field_dims = _vocab_sizes()
    model = DeepFM(
        field_dims,
        num_dense=len(dense_cols),
        embed_dim=16,
        mlp_dims=(128, 64),
        dropout=0.2
    )

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    loss_fn   = nn.BCEWithLogitsLoss()

    # è®­ç»ƒ & éªŒè¯å¾ªç¯
    for ep in range(1, epochs + 1):
        # è®­ç»ƒ
        model.train()
        total_loss, count = 0.0, 0
        for Xs, Xd, y in tqdm(train_loader, desc=f"Ep {ep}/{epochs}", ncols=80):
            Xs, Xd, y = Xs.to(device), Xd.to(device), y.to(device)
            optimizer.zero_grad()
            loss = loss_fn(model(Xs, Xd), y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * y.size(0)
            count += y.size(0)
        print(f"  train_loss={total_loss/count:.4f}")

        # éªŒè¯
        model.eval()
        total_val, count_val = 0.0, 0
        with torch.no_grad():
            for Xs, Xd, y in val_loader:
                Xs, Xd, y = Xs.to(device), Xd.to(device), y.to(device)
                v_loss = loss_fn(model(Xs, Xd), y).item()
                total_val += v_loss * y.size(0)
                count_val += y.size(0)
        print(f"  val_loss  ={total_val/count_val:.4f}")

    # ä¿å­˜æ¨¡å‹
    torch.save(model.cpu().state_dict(), MODEL_PATH)
    print("DeepFM saved â†’", MODEL_PATH)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--epochs",    type=int, default=3)
    parser.add_argument("--batch",     type=int, default=2048)
    parser.add_argument("--neg_ratio", type=int, default=1)
    args = parser.parse_args()
    main(args.epochs, args.batch, args.neg_ratio)

===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/torchfm_ranker.py =====
"""
torchfm_ranker.py
"""

from pathlib import Path
from typing import Sequence

import torch
# from torchfm.deepfm import DeepFM
from DNN_TorchFM_TTower.models.ranking.torchfm.deepfm import DeepFM

MODEL_PATH = Path("saved_model/deepfm_ranker.pt")


def create_model(field_dims: Sequence[int],
                 embed_dim: int = 16):
    """
    field_dims : List[int]  æ¯ä¸ª sparse ç‰¹å¾ï¼ˆuser_id, movie_id, genre_idï¼‰çš„ vocab_size
    """
    model = DeepFM(field_dims,
                   embed_dim=embed_dim,
                   mlp_dims=(128, 64),
                   dropout=0.2)
    return model


def save_model(model: torch.nn.Module) -> None:
    MODEL_PATH.parent.mkdir(exist_ok=True)
    torch.save(model.state_dict(), MODEL_PATH)


def load_model(field_dims: Sequence[int]):
    """
    è‹¥æ¨¡å‹æ–‡ä»¶å­˜åœ¨åˆ™åŠ è½½å¹¶è¿”å› eval() åæ¨¡å‹ï¼Œå¦åˆ™è¿”å› Noneã€‚

    å½“æ•°æ®åº“ä¸­æ–°å¢äº†ç”¨æˆ·æˆ–ç”µå½±æ—¶ï¼Œåªæ¢å¤å·²æœ‰çš„è¡Œï¼Œæ–°å¢åŠ çš„ embedding è¡Œä¿æŒéšæœºåˆå§‹åŒ–ã€‚
    """
    if MODEL_PATH.exists():
        # 1) æ„å»ºä¸€ä¸ªæŒ‰æœ€æ–° field_dims å¤§å°åˆå§‹åŒ–çš„ç½‘ç»œ
        m = create_model(field_dims)
        # 2) åªæ¢å¤å·²è®­ç»ƒå¥½çš„æƒé‡è¡Œï¼Œstrict=False ä¿ç•™äº†æ–°åŠ è¡Œçš„éšæœºåˆå§‹åŒ–
        m.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"), strict=False)
        m.eval()
        return m
    return None


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/feature_engineer.py =====
# DNN_TorchFM_TTower/models/ranking/feature_engineer.py

"""
Assemble features for DeepFM training and inference,
now including the user's preferred genre as an extra sparse field.
"""

from collections import defaultdict
from typing import List
import pandas as pd

from DNN_TorchFM_TTower.models.db import fetchall_dict, fetchone_dict

def _get_movie_features() -> pd.DataFrame:
    rows = fetchall_dict("""
        SELECT movie_id, genre_id
        FROM movie_genre
        ORDER BY movie_id, genre_id
    """)
    first_genre = {}
    for r in rows:
        first_genre.setdefault(r["movie_id"], r["genre_id"])

    rows = fetchall_dict("""
        SELECT id AS movie_id,
               vote_average,
               popularity
        FROM movies
    """)
    for r in rows:
        r["genre_id"] = first_genre.get(r["movie_id"], 0)
    return pd.DataFrame(rows)

def _get_user_features() -> pd.DataFrame:
    rows = fetchall_dict("SELECT id AS user_id, COALESCE(age, 0) AS age FROM users")
    return pd.DataFrame(rows)

def build_training_df(neg_ratio: int = 1) -> pd.DataFrame:
    pos_rows = fetchall_dict("SELECT user_id, movie_id FROM view_history")
    if not pos_rows:
        return pd.DataFrame()

    pos_df = pd.DataFrame(pos_rows)
    pos_df["label"] = 1

    all_movies = {r["movie_id"] for r in fetchall_dict("SELECT id AS movie_id FROM movies")}
    user_pos  = defaultdict(set)
    for r in pos_rows:
        user_pos[r["user_id"]].add(r["movie_id"])

    import random
    neg_records = []
    for u, watched in user_pos.items():
        cand = list(all_movies - watched)
        k = min(len(cand), neg_ratio * len(watched))
        for m in random.sample(cand, k):
            neg_records.append({"user_id": u, "movie_id": m, "label": 0})
    neg_df = pd.DataFrame(neg_records)

    data_df = pd.concat([pos_df, neg_df], ignore_index=True)

    movies_df = _get_movie_features()
    users_df  = _get_user_features()

    df = data_df.merge(movies_df, on="movie_id", how="left") \
                .merge(users_df,  on="user_id", how="left")

    # <-- NEW: attach the user's chosen genre -->
    pref_rows = fetchall_dict("SELECT user_id, genre_id AS pref_genre_id FROM user_preferences")
    pref_df   = pd.DataFrame(pref_rows)
    df = df.merge(pref_df, on="user_id", how="left")
    df["pref_genre_id"].fillna(0, inplace=True)
    df["pref_genre_id"] = df["pref_genre_id"].astype(int)

    df.fillna(0, inplace=True)
    return df

def build_infer_df(
    user_id: int,
    movie_ids: List[int],
    recall_scores: List[float]
) -> pd.DataFrame:
    movies_df = _get_movie_features()
    users_df  = _get_user_features()

    infer_df = pd.DataFrame({
        "user_id":      user_id,
        "movie_id":     movie_ids,
        "recall_score": recall_scores,
    })

    # <-- NEW: single preference for inference -->
    pref_rows = fetchall_dict(
        "SELECT genre_id AS pref_genre_id FROM user_preferences WHERE user_id = %s",
        (user_id,)
    )
    if pref_rows:
        pref_id = pref_rows[0]["pref_genre_id"]
    else:
        pref_id = 0
    infer_df["pref_genre_id"] = pref_id

    infer_df = infer_df.merge(movies_df, on="movie_id", how="left") \
                       .merge(users_df,  on="user_id",  how="left")

    infer_df.fillna(0, inplace=True)
    return infer_df


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/__init__.py =====


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/custom_deepfm.py =====
"""
çº¯ PyTorch å®ç°çš„ DeepFM
æ”¯æŒ:
  â€¢ sparse_x : LongTensor (batch, num_sparse_fields)
  â€¢ dense_x  : FloatTensor (batch, num_dense_fields)
è¾“å‡º raw logit (BCEWithLogitsLoss å¯¹åº”)
"""

import torch
import torch.nn as nn


class FeaturesLinear(nn.Module):
    """ y = Î£ w_i + b  ï¼ˆä¸€é˜¶é¡¹ï¼‰ """
    def __init__(self, field_dims):
        super().__init__()
        self.fc = nn.Embedding(sum(field_dims), 1)
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        # x.shape = (B, F)  æ¯ä¸ªå…ƒç´ éƒ½æ˜¯â€œåœ¨å…¶ field çš„å…¨å±€åç§» idâ€
        return self.fc(x).sum(dim=1) + self.bias


class DenseLinear(nn.Module):
    """ ä¸€é˜¶ denseï¼š y = wÂ·x """
    def __init__(self, num_dense):
        super().__init__()
        self.fc = nn.Linear(num_dense, 1, bias=False)

    def forward(self, x):
        return self.fc(x)


class FeaturesEmbedding(nn.Module):
    """ äºŒé˜¶ / Deep éƒ¨åˆ†å…¬ç”¨çš„ embedding """
    def __init__(self, field_dims, embed_dim):
        super().__init__()
        self.embedding = nn.Embedding(sum(field_dims), embed_dim)

    def forward(self, x):
        return self.embedding(x)          # (B, F, D)


class FactorizationMachine(nn.Module):
    """ FM äºŒé˜¶äº¤å‰é¡¹ Î£âŸ¨v_i, v_jâŸ© """
    def forward(self, embed_x):
        # embed_x : (B, F, D)
        square_of_sum = embed_x.sum(dim=1) ** 2        # (B, D)
        sum_of_square = (embed_x ** 2).sum(dim=1)      # (B, D)
        ix = 0.5 * (square_of_sum - sum_of_square)     # (B, D)
        return ix.sum(dim=1, keepdim=True)             # (B, 1)


class MLP(nn.Module):
    def __init__(self, in_dim, dims, dropout):
        super().__init__()
        layers = []
        for dim in dims:
            layers += [nn.Linear(in_dim, dim),
                       nn.ReLU(),
                       nn.Dropout(dropout)]
            in_dim = dim
        self.mlp = nn.Sequential(*layers)

    def forward(self, x):
        return self.mlp(x)       # (B, last_dim)


class DeepFM(nn.Module):
    def __init__(self,
                 field_dims,          # List[int] sparse vocab_sizes
                 num_dense,           # int
                 embed_dim=16,
                 mlp_dims=(128, 64),
                 dropout=0.2):
        super().__init__()
        self.num_dense = num_dense

        self.linear_sparse = FeaturesLinear(field_dims)
        self.linear_dense  = DenseLinear(num_dense)

        self.embedding = FeaturesEmbedding(field_dims, embed_dim)
        self.fm = FactorizationMachine()

        dnn_input_dim = len(field_dims) * embed_dim + num_dense
        self.mlp = MLP(dnn_input_dim, mlp_dims, dropout)
        self.mlp_out = nn.Linear(mlp_dims[-1], 1)

    def forward(self, sparse_x, dense_x):
        """
        sparse_x : LongTensor (B, F_s)
        dense_x  : FloatTensor(B, F_d)
        """
        embed_x = self.embedding(sparse_x)           # (B, Fs, D)

        linear_term = self.linear_sparse(sparse_x) + self.linear_dense(dense_x)
        fm_term     = self.fm(embed_x)               # (B, 1)

        dnn_input   = torch.cat([embed_x.reshape(embed_x.size(0), -1),
                                 dense_x], dim=1)
        dnn_term    = self.mlp_out(self.mlp(dnn_input))  # (B, 1)

        logit = linear_term + fm_term + dnn_term     # (B, 1)
        return logit.squeeze(1)                      # (B,)


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/infer_ranking.py =====
# DNN_TorchFM_TTower/models/ranking/infer_ranking.py

import numpy as np
import torch
from pathlib import Path

from DNN_TorchFM_TTower.models.db import fetchone_dict
from DNN_TorchFM_TTower.models.ranking.feature_engineer import build_infer_df
from DNN_TorchFM_TTower.models.ranking.custom_deepfm import DeepFM

BASE_DIR  = Path(__file__).resolve().parents[3]
MODEL_PATH = BASE_DIR / "saved_model" / "deepfm_ranker.pt"

def _vocab_sizes():
    mu = fetchone_dict("SELECT MAX(id) AS m FROM users")["m"] or 0
    mm = fetchone_dict("SELECT MAX(id) AS m FROM movies")["m"] or 0
    mg = fetchone_dict("SELECT MAX(id) AS m FROM genres")["m"] or 0
    return [mu + 2, mm + 2, mg + 2, mg + 2]

def _load_model(field_dims, num_dense):
    model = DeepFM(field_dims, num_dense)
    if not MODEL_PATH.exists():
        return None

    state_old = torch.load(MODEL_PATH, map_location="cpu")

    def _safe_copy(param_name, new_weight):
        if param_name in state_old:
            old_w = state_old[param_name]
            rows  = min(old_w.size(0), new_weight.size(0))
            new_weight[:rows].data.copy_(old_w[:rows])

    _safe_copy("linear_sparse.fc.weight",    model.linear_sparse.fc.weight)
    _safe_copy("embedding.embedding.weight", model.embedding.embedding.weight)

    state_old.pop("linear_sparse.fc.weight",    None)
    state_old.pop("embedding.embedding.weight", None)

    model.load_state_dict(state_old, strict=False)
    model.eval()
    return model

def rank_candidates(user_id, movie_ids, recall_scores, top_n=10):
    if not movie_ids:
        return []

    df = build_infer_df(user_id, movie_ids, recall_scores)
    sparse_cols = ["user_id", "movie_id", "genre_id", "pref_genre_id"]
    dense_cols  = ["recall_score", "vote_average", "popularity", "age"]

    field_dims = _vocab_sizes()
    model      = _load_model(field_dims, num_dense=len(dense_cols))
    if model is None:
        idx = np.argsort(-np.array(recall_scores))[:top_n]
        return list(np.array(movie_ids)[idx])

    xs = torch.tensor(df[sparse_cols].values, dtype=torch.long)
    xd = torch.tensor(df[dense_cols].values, dtype=torch.float32)
    with torch.no_grad():
        scores = torch.sigmoid(model(xs, xd)).numpy()

    df["score"] = scores
    return df.sort_values("score", ascending=False).head(top_n)["movie_id"].tolist()

if __name__ == "__main__":
    import argparse
    from DNN_TorchFM_TTower.models.db import get_movie_titles
    from DNN_TorchFM_TTower.models.recall.two_tower import load_model, recommend_warm_start

    ap = argparse.ArgumentParser()
    ap.add_argument("user_id", type=int)
    args = ap.parse_args()

    tower = load_model()
    cids, cscs = recommend_warm_start(tower, args.user_id, top_n=300)
    ranked = rank_candidates(args.user_id, cids, cscs, top_n=10)
    titles = get_movie_titles(ranked)
    for i, mid in enumerate(ranked, start=1):
        print(f"{i:02}. {titles.get(mid,'Unknown')} (ID={mid})")


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/models/ranking/torchfm/deepfm.py =====
# DNN_TorchFM_TTower\models\ranking\torchfm\deepfm.py
import torch
import torch.nn as nn
import torch.nn.functional as F


class FeaturesLinear(nn.Module):
    def __init__(self, field_dims):
        super().__init__()
        self.fc = nn.Embedding(sum(field_dims), 1)
        self.bias = nn.Parameter(torch.zeros((1,)))

    def forward(self, x):
        return torch.sum(self.fc(x), dim=1) + self.bias


class FeaturesEmbedding(nn.Module):
    def __init__(self, field_dims, embed_dim):
        super().__init__()
        self.embedding = nn.Embedding(sum(field_dims), embed_dim)

    def forward(self, x):
        return self.embedding(x)


class MultiLayerPerceptron(nn.Module):
    def __init__(self, input_dim, dims, dropout):
        super().__init__()
        layers = []
        for dim in dims:
            layers.append(nn.Linear(input_dim, dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(p=dropout))
            input_dim = dim
        self.mlp = nn.Sequential(*layers)

    def forward(self, x):
        return self.mlp(x)


class DeepFM(nn.Module):
    def __init__(self, field_dims, embed_dim, mlp_dims, dropout):
        super().__init__()
        self.embedding = FeaturesEmbedding(field_dims, embed_dim)
        self.linear = FeaturesLinear(field_dims)
        self.fm = FactorizationMachine(reduce_sum=True)
        self.mlp = MultiLayerPerceptron(len(field_dims) * embed_dim, mlp_dims, dropout)

    def forward(self, x):
        embed_x = self.embedding(x)
        x = self.linear(x) + self.fm(embed_x) + torch.sum(self.mlp(embed_x.view(embed_x.size(0), -1)), dim=1, keepdim=True)
        return torch.sigmoid(x.squeeze(1))


class FactorizationMachine(nn.Module):
    def __init__(self, reduce_sum=True):
        super().__init__()
        self.reduce_sum = reduce_sum

    def forward(self, x):
        square_of_sum = torch.sum(x, dim=1) ** 2
        sum_of_square = torch.sum(x ** 2, dim=1)
        ix = square_of_sum - sum_of_square
        if self.reduce_sum:
            ix = torch.sum(ix, dim=1, keepdim=True)
        return 0.5 * ix


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/service/recommender copy.py =====
# service/recommender.py

"""
ç»Ÿä¸€æ¨èå…¥å£ï¼š
    â€¢ æ–°ç”¨æˆ·       â†’ å†·å¯åŠ¨ (PopRec + éšæœºå¤šæ ·åŒ–)
    â€¢ è€ç”¨æˆ·       â†’ Two-Tower å¬å›  â†’ DeepFM ç²¾æ’
å¯¹ä¸Šå±‚è°ƒç”¨è€…éšè—å®ç°ç»†èŠ‚ï¼Œåªæš´éœ²ä¸€ä¸ªå‡½æ•° `recommend_movies_for_user`
"""

from __future__ import annotations

import functools
import time
from typing import List, Tuple

from models.db import get_user_view_count
from models.recall import cold_start
from models.recall.two_tower import load_model as _load_tower, recommend_warm_start
from models.ranking.infer_ranking import rank_candidates

# --------------------------------------------------------------------------- #
#                          å…¨å±€ç¼“å­˜ â€”â€” åªåŠ è½½ä¸€æ¬¡                              #
# --------------------------------------------------------------------------- #
_TOWER_MODEL = functools.lru_cache(maxsize=1)(_load_tower)()   # type: ignore


# --------------------------------------------------------------------------- #
#                          æ ¸ å¿ƒ æ¥ å£                                        #
# --------------------------------------------------------------------------- #
def recommend_movies_for_user(user_id: int,
                              n_recall: int = 300,
                              n_final: int = 20
                              ) -> List[int]:
    """
    è¿”å›æœ€ç»ˆæ¨èçš„ movie_id åˆ—è¡¨ (é•¿åº¦ n_finalï¼Œä¸å«é‡å¤)ã€‚
    è‹¥ç²¾æ’æ¨¡å‹æœªè®­ç»ƒï¼Œåˆ™ç›´æ¥æŒ‰å¬å›åˆ†æ’åºã€‚
    """
    t0 = time.time()
    view_cnt = get_user_view_count(user_id)

    # -------- å†·å¯åŠ¨ --------
    if view_cnt == 0:
        print(f"[recommender] user {user_id} cold-start")
        movie_ids = cold_start.recommend_cold_start(top_n=n_final)
        print(f"[recommender] cold-start done ({len(movie_ids)} items, {time.time()-t0:.2f}s)")
        return movie_ids

    # -------- çƒ­å¯åŠ¨ï¼šå¬å› --------
    recall_ids, recall_scores = recommend_warm_start(
        _TOWER_MODEL, user_id, top_n=n_recall
    )
    if not recall_ids:
        # å›é€€ï¼šå†·å¯åŠ¨
        print(f"[recommender] warm-start empty, fallback to cold")
        return cold_start.recommend_cold_start(top_n=n_final)

    # -------- ç²¾æ’ --------
    ranked = rank_candidates(user_id, recall_ids, recall_scores, top_n=n_final)
    print(f"[recommender] warm-start+rank done ({len(ranked)} items, {time.time()-t0:.2f}s)")
    return ranked


# --------------------------------------------------------------------------- #
#                           CLI æµ‹ è¯•                                          #
# --------------------------------------------------------------------------- #
if __name__ == "__main__":
    import argparse
    from models.db import get_movie_titles

    ap = argparse.ArgumentParser()
    ap.add_argument("user_id", type=int)
    ap.add_argument("--top", type=int, default=10)
    args = ap.parse_args()

    mids = recommend_movies_for_user(args.user_id, n_final=args.top)
    titles = get_movie_titles(mids)

    print("\næ¨èç»“æœï¼š")
    for i, mid in enumerate(mids, 1):
        print(f"{i:02}. {titles.get(mid, 'Unknown')}  (ID={mid})")


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/service/__init__.py =====


===== æ–‡ä»¶: ./DNN_TorchFM_TTower/service/recommender.py =====
# service/recommender.py

"""
ç»Ÿä¸€æ¨èå…¥å£ï¼š
    â€¢ æ–°ç”¨æˆ·       â†’ å†·å¯åŠ¨ (PopRec + éšæœºå¤šæ ·åŒ–)
    â€¢ è€ç”¨æˆ·       â†’ Two-Tower å¬å›  â†’ DeepFM ç²¾æ’
å¯¹ä¸Šå±‚è°ƒç”¨è€…éšè—å®ç°ç»†èŠ‚ï¼Œåªæš´éœ²ä¸€ä¸ªå‡½æ•° `recommend_movies_for_user`
"""

from __future__ import annotations

import time
from typing import Tuple

from DNN_TorchFM_TTower.models.db import (
    get_user_view_count,
    fetchone_dict,
    execute_sql,
)
from DNN_TorchFM_TTower.models.recall import cold_start
from DNN_TorchFM_TTower.models.recall.two_tower import load_model as _load_tower, recommend_warm_start
from DNN_TorchFM_TTower.models.ranking.infer_ranking import rank_candidates


def _get_tower_model():
    """
    æ¯æ¬¡éƒ½åŠ¨æ€åŠ è½½ Two-Tower æ¨¡å‹ï¼Œä»¥ä¿è¯ä½¿ç”¨æœ€æ–°çš„ vocab sizeã€‚
    """
    return _load_tower()


def recommend_movies_for_user(user_id: int,
                              n_recall: int = 300,
                              n_final:  int = 20
                              ) -> Tuple[list[int], list[float], str]:
    """
    è¿”å› (movie_ids, scores, strategy)
      - strategy: 'cold' | 'warm' | 'warm+rank'
    """

    # 1) ç¡®ä¿æ–°ç”¨æˆ·åœ¨ users è¡¨ä¸­æœ‰è®°å½•
    if not fetchone_dict("SELECT 1 FROM users WHERE id=%s", (user_id,)):
        execute_sql(
            "INSERT INTO users (id, email, password_hash) VALUES (%s, %s, %s)",
            (user_id, f"api_{user_id}@demo.com", b"hash_placeholder"),
        )

    # 2) è·å–ç”¨æˆ·å†å²è§‚çœ‹æ¬¡æ•°
    view_cnt = get_user_view_count(user_id)

    # -------- å†·å¯åŠ¨ --------
    if view_cnt == 0:
        mids = cold_start.recommend_cold_start(top_n=n_final)
        return mids, [None] * len(mids), "cold"

    # -------- çƒ­å¯åŠ¨ (Two-Tower) + fallback --------
    recall_model = _get_tower_model()
    try:
        recall_ids, recall_scores = recommend_warm_start(
            recall_model, user_id, top_n=n_recall
        )
    except IndexError:
        # Embedding è¶Šç•Œï¼Œæ–°ç”¨æˆ·/æ–°ç”µå½±å°šæœªåœ¨æ¨¡å‹ä¸­ï¼šfallback åˆ°å†·å¯åŠ¨
        print(f"[recommender] user {user_id} embedding è¶Šç•Œï¼Œfallback cold-start")
        mids = cold_start.recommend_cold_start(top_n=n_final)
        return mids, [None] * len(mids), "cold"

    if not recall_ids:
        mids = cold_start.recommend_cold_start(top_n=n_final)
        return mids, [None] * len(mids), "cold"

    # -------- DeepFM ç²¾æ’ --------
    mids = rank_candidates(user_id, recall_ids, recall_scores, top_n=n_final)
    return mids, recall_scores[:n_final], "warm+rank"


# -------------------- CLI æµ‹è¯• --------------------
if __name__ == "__main__":
    import json
    import datetime
    import argparse
    from DNN_TorchFM_TTower.models.db import get_movie_titles

    ap = argparse.ArgumentParser()
    ap.add_argument("user_id", type=int)
    ap.add_argument("--top", type=int, default=10)
    args = ap.parse_args()

    mids, scores, strategy = recommend_movies_for_user(args.user_id, n_final=args.top)
    titles = get_movie_titles(mids)
    payload = {
        "user_id": args.user_id,
        "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
        "strategy": strategy,
        "items": [
            {
                "rank": i + 1,
                "movie_id": mid,
                "title": titles.get(mid, "Unknown"),
                "score": float(scores[i]) if scores[i] is not None else None,
            }
            for i, mid in enumerate(mids)
        ],
    }
    print(json.dumps(payload, ensure_ascii=False, indent=2))

